{
  "name" : "Convexification",
  "cells" : [ {
    "id" : 0,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "Convexifying Matrix Factorization",
      "extraFields" : { }
    }
  }, {
    "id" : 1,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "### Matrix Factorization as a Rank-Constrained Problem\nMatrix \\\\( Y\\in\\Re^{n,d} \\\\). For any \\(( K \\in \\mathbbb{N} \\\\),\n- \\\\( Y_{ij} = <U_i, V_j> \\\\)\n",
      "extraFields" : { }
    }
  }, {
    "id" : 2,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "History",
      "extraFields" : { }
    }
  }, {
    "id" : 3,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "History of Convex Factorization\n\n* 2001: Fazel, Maryam, Haitham Hindi, Stephen P Boyd. \"A rank minimization heuristic with application to minimum order system approximation.\n* 2009: CandÃ¨s, Emmanuel J, and Benjamin Recht. \"Exact matrix completion via convex optimization.\".\n* 2009: Wright, John, Arvind Ganesh, Shankar Rao, Yigang Peng, and Yi Ma. \"Robust principal component analysis\".\n* 2011: Tamioka et Suzu. Statistical performance of convex tensor decomposition.\n* 2013: Bouchard et al. Convex Collective Matrix Factorization.\n\n",
      "extraFields" : { }
    }
  }, {
    "id" : 4,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "Consequences\n\n",
      "extraFields" : { }
    }
  }, {
    "id" : 5,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "### What Do We Gain By Making the Problem Convex?\nWe open the Pandor box of convex optimization tools!\n\nTheoretical guarantees\n\n- Convergence to the global optimum, no need for smart initialization\n- Speed of convergences\n- Polynomial time guarantees for a fixed accuracy \n\nBut more importantly, new algorithms:\n\n- Proximal methods (ISTA and FISTA)\n- Frank-Wolfe (Conjugate Gradient) algorithms\n- Augmented Lagrangian approaches (ADMM, splitting methods)\n- Stochastic variants\n",
      "extraFields" : { }
    }
  }, {
    "id" : 6,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "Combining regularization\n",
      "extraFields" : { }
    }
  }, {
    "id" : 7,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "// Matrices!\nval random = new scala.util.Random()\nMatrix((0 until 10).map(i => (0 until 10).map(j => (i+j)+2*random.nextDouble())))",
      "extraFields" : { }
    }
  }, {
    "id" : 8,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "\\begin{equation}\n\\begin{array}{cc}a&b\\\\\nc&d\n\\end{array}\n\\end{equation}",
      "extraFields" : { }
    }
  }, {
    "id" : 9,
    "compiler" : "scala",
    "input" : {
      "sessionId" : null,
      "code" : "f(10)",
      "extraFields" : {
        "aggregatedCells" : "[]"
      }
    }
  } ],
  "config" : { }
}
