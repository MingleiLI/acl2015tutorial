{
  "name" : "Non-Negative Matrix Factorization",
  "cells" : [ {
    "id" : 0,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "why",
      "extraFields" : { }
    }
  }, {
    "id" : 1,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "### Non-negativity\n\n- Intepretability\n  - zero has special meaning\n\n- Modelling assumptions:\n  - negative objects in images\n  - negative topics in documents\n",
      "extraFields" : { }
    }
  }, {
    "id" : 2,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "definition",
      "extraFields" : { }
    }
  }, {
    "id" : 3,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "## Definition\n\nGiven (fully observed) \\\\(\\mathbf{Y} \\in\\Re^{N\\times M} \\geq 0\\\\)\n\nFind \\\\(\\mathbf{U} \\in\\Re^{N\\times L} \\geq 0 \\\\) and \\\\(\\mathbf{V} \\in\\Re^{M\\times L} \\geq 0\\\\)\n\nthat minimize \\\\(||\\mathbf{Y} - \\mathbf{U}\\mathbf{V}^{T}|| _2\\\\)",
      "extraFields" : { }
    }
  }, {
    "id" : 4,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "algos",
      "extraFields" : { }
    }
  }, {
    "id" : 5,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "### Algorithm\n\nMultiplicative update rules (Lee and Seung, 2001):\n\n\\\\(u_{n,l} = u_{n,l} \\frac{(\\mathbf{Y}\\mathbf{V})_{n,l}}{(\\mathbf{Y}\\mathbf{Y}^{T}\\mathbf{U})_{n,l}} \\\\)\n\n\\\\(v_{m,l} = v_{m,l} \\frac{(\\mathbf{Y}^T\\mathbf{U})_{m,l}}{(\\mathbf{Y}^{T}\\mathbf{Y}\\mathbf{V})_{m,l}} \\\\)\n\nRelated to the additive SGD updates\n\n\n\n",
      "extraFields" : { }
    }
  }, {
    "id" : 6,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "plsa",
      "extraFields" : { }
    }
  }, {
    "id" : 7,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "### Probabilstic Latent Semantic Analysis\n\n\nSimilar updates if the matrices are normalized probability distributions with KL divergence as loss, becomes equivalent to pLSI.\n\n",
      "extraFields" : { }
    }
  }, {
    "id" : 8,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "lda",
      "extraFields" : { }
    }
  }, {
    "id" : 9,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "### Topic models\n\nEye candy\n\nShow how the topics correspond to the factors\n\nrecent work in topic modelling goes back to MF",
      "extraFields" : { }
    }
  }, {
    "id" : 10,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "sparsity",
      "extraFields" : {
        "hide_output" : "false"
      }
    }
  }, {
    "id" : 11,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "### Sparsity in NMF\n\n- better interpretability (fewer latent factors active per instance)\n- modelling flexibility\n\nFraction of zeros\n \nDefinition:<!-- .element: class=\"fragment\" data-fragment-index=\"1\" -->\n",
      "extraFields" : { }
    }
  } ],
  "config" : { }
}
