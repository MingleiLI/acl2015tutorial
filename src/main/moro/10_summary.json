{
  "name" : "Summary",
  "cells" : [ {
    "id" : 0,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "bef",
      "extraFields" : { }
    }
  }, {
    "id" : 1,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "### Before the break\n\n1. Matrices/Tensor = natural concepts for relations\n2. Low-Rank = natural regularization\n3. Non-negativity => Clustering\n4. Binary loss: much better than squared loss\n ",
      "extraFields" : { }
    }
  }, {
    "id" : 2,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "aft",
      "extraFields" : { }
    }
  }, {
    "id" : 3,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "### After the break\n\n5. Prior knowledge included using *logic*-based loss models\n6. Multi-relational learning\n    - Tensors: *many* different possible factorizations\n    - Collective Matrix Factorization for *typed* data\n8. Discriminative factoriation\n    - Reduced rank regression/Multi-task learning\n    - Factorization machines\n    - Structured prediction\n9. Convexification\n    - The *trace norm* is a real breakthrough\n    - Theoretical guarantees, new algorithms, structured regularization",
      "extraFields" : { }
    }
  }, {
    "id" : 4,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "takehome",
      "extraFields" : { }
    }
  }, {
    "id" : 5,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "### Take-home messages\n\nNLP is about learning relations. Low-rank factorization simply *works*\n\n- in *theory*: well understood model with nearly **linear-time** complexity\n- in *practice*: many **large scale** examples\n\nThe real reason why it works: \n\nReplaces **combinatorics** by **linear algebra**\n\n\n",
      "extraFields" : { }
    }
  }, {
    "id" : 6,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "toolkits",
      "extraFields" : { }
    }
  }, {
    "id" : 7,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "### Toolkits\n\n- R Package for Collective Matrix Factorization (Klami)\n[https://cran.r-project.org/web/packages/CMF]()\n\n- MyMediaLite (Ganter & Rendle): [http://mymedialite.net/news/index.html]()\n\n- scikit-tensor (Nickel): [http://github.com/mnick/scikit-tensor]()\n\n- NMF-MATLAB (Yi & Ngom): [https://sites.google.com/site/nmftool/]()\n\n- Theano (Bengio et al.): [http://deeplearning.net/software/theano/]()\n\n- Wolfe (Riedel et al.): [http://www.wolfe.ml]()\n    - used in this presentation via Moro by Sameer Singh\n",
      "extraFields" : { }
    }
  }, {
    "id" : 8,
    "compiler" : "section",
    "input" : {
      "sessionId" : null,
      "code" : "end",
      "extraFields" : { }
    }
  }, {
    "id" : 9,
    "compiler" : "markdown",
    "input" : {
      "sessionId" : null,
      "code" : "\n\n<img src=\"../../assets/figures/readTheMatrix.png\" height=\"700\">",
      "extraFields" : { }
    }
  } ],
  "config" : { }
}
